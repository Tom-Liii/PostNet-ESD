{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('..')\n",
    "print(\"Current Working Directory \" , os.getcwd())\n",
    "import sys\n",
    "sys.path.append(\"../\") # Add directory containing src/data to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.posterior_networks.run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "directory_dataset='../data'\n",
    "dataset_name='MNIST'\n",
    "ood_dataset_names=['KMNIST', 'FashionMNIST']\n",
    "unscaled_ood=True\n",
    "split=[.6, .8]\n",
    "transform_min=0.\n",
    "transform_max=255.\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='../saved_models'\n",
    "architecture='conv'\n",
    "input_dims=[28, 28, 1]\n",
    "output_dim=10\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=5\n",
    "latent_dim=6\n",
    "no_density=False\n",
    "density_type='radial_flow'\n",
    "n_density=6\n",
    "k_lipschitz=None\n",
    "budget_function='id'\n",
    "\n",
    "# Training parameters\n",
    "directory_results='../saved_results'\n",
    "max_epochs=200\n",
    "patience=10\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=5e-5\n",
    "loss='UCE'\n",
    "training_mode='joint'\n",
    "regr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_metrics = run(# Dataset parameters\n",
    "                        seed_dataset,  # Seed to shuffle dataset. int\n",
    "                        directory_dataset,  # Path to dataset. string\n",
    "                        dataset_name,  # Dataset name. string\n",
    "                        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "                        unscaled_ood,  # If true consider also unscaled versions of ood datasets. boolean\n",
    "                        split,  # Split for train/val/test sets. list of floats\n",
    "                        transform_min,  # Minimum value for rescaling input data. float\n",
    "                        transform_max,  # Maximum value for rescaling input data. float\n",
    "\n",
    "                        # Architecture parameters\n",
    "                        seed_model,  # Seed to init model. int\n",
    "                        directory_model,  # Path to save model. string\n",
    "                        architecture,  # Encoder architecture name. string\n",
    "                        input_dims,  # Input dimension. List of ints\n",
    "                        output_dim,  # Output dimension. int\n",
    "                        hidden_dims,  # Hidden dimensions. list of ints\n",
    "                        kernel_dim,  # Input dimension. int\n",
    "                        latent_dim,  # Latent dimension. int\n",
    "                        no_density,  # Use density estimation or not. boolean\n",
    "                        density_type,  # Density type. string\n",
    "                        n_density,  # Number of density components. int\n",
    "                        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "                        budget_function,  # Budget function name applied on class count. name\n",
    "\n",
    "                        # Training parameters\n",
    "                        directory_results,  # Path to save resutls. string\n",
    "                        max_epochs,  # Maximum number of epochs for training\n",
    "                        patience,  # Patience for early stopping. int\n",
    "                        frequency,  # Frequency for early stopping test. int\n",
    "                        batch_size,  # Batch size. int\n",
    "                        lr,  # Learning rate. float\n",
    "                        loss,  # Loss name. string\n",
    "                        training_mode,  # 'joint' or 'sequential' training. string\n",
    "                        regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_metrics['model_path'])\n",
    "print(results_metrics['result_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_show = ['model_path', 'result_path', 'train_losses', 'val_losses', 'test_losses', 'train_accuracies', 'val_accuracies', 'test_accuracies', 'fail_trace']\n",
    "for k, v in results_metrics.items():\n",
    "    if k not in no_show:\n",
    "        print(k, v)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
